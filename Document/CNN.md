# 卷积神经网络

卷积神经网络是神经网络中一种应用范围最广的模型，常用来对图像进行分类。神经网络中最基本的元素是神经元，如下图所示，表示了一个 MP 神经元模型，由输入信号、权值、求和节点、激活函数共同构成。

<div align = 'center'><img src = '..\Document\pic\屏幕截图 2023-11-23 141706.png' width = '500' title = 'MP 神经元模型'></div>

其中， $X_n$ 表示本神经元从上一层接收到的 n 个其他神经元信号，这些信号是带有权值比重 $W_{kn}$ 的，k 表示第 k 个神经元，n 表示第 n 个输入。求和节点对上一层 n 个神经元的权重信息进行求和处理，通过与本神经元的阈值做比较后输入到激活函数进行激活操作，最终得到输出结果，最终输出表示本神经元对上一层 n 个神经元的反馈。

全连接网络中的每个神经元都与前一层的所有神经元相连，这导致了大量的连接和参数。这样的结构在处理大规模数据时可能会导致参数量巨大，使得网络训练的复杂性增加。这种复杂性不仅可能导致训练速度减慢，还容易导致过拟合，即网络在训练数据上表现很好，但在新数据上的泛化能力较差。

为了解决全连接网络的问题，研究者引入了卷积神经网络的概念。CNNs 利用了局部连接和权值共享的特性。局部连接指的是每个神经元仅与输入数据的一小部分相连，而不是整个数据。这样的局部连接允许网络关注于输入的局部特征，而不是整体特征。权值共享是指在整个输入空间中使用相同的权值来检测不同位置的相似特征。这两个特性有效地减少了参数数量。

利用局部连接和权值共享，CNNs 加快了网络的训练速度，因为减少了需要学习的参数数量。此外，它提高了网络的性能，因为网络更加关注数据的局部结构，有助于提取和学习更具有层次性和抽象性的特征，使得网络更具有泛化能力，减少过拟合的风险。

## 卷积层

如下图所示，采用大小为 $3\times 3$ 的卷积核去提取一个 $4\times 4$ 输入图的特征，在卷积运算中，卷积核在输入图矩阵中滑动 1 距离单位以完成线性运算，运算结果加上偏置值再通过激活函数后将结果放置到 $2\times 2$ 输出图的对应位置。

<div align = 'center'><img src = '..\Document\pic\屏幕截图 2023-11-23 142439.png' width = '500' title = '卷积运算'></div>

在卷积过程中，所做的点积运算是线性的，激活函数的作用就是添加非线性的计算。在以往的传统研究中，研究者大多使用 Logistic-Sigmoi 函数：

$$f(x) = \frac{1}{1+e^{-x}}$$

或者是 Sigmoid 函数的变形 tanh 函数来作为激活函数应用于卷积层中。

$$f(x) = \tanh(x) = \frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}$$

然而，Sigmoid 函数容易饱和且存在收敛缓慢的问题。tanh 函数的工作原理与 Sigmoid 函数十分相似，不同之处在于tanh 函数基本是零均值的，可以弥补 Sigmoid 函数中收敛缓慢的问题，但是它还是存在梯度饱和的问题。

