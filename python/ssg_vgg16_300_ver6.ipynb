{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff3745b3",
   "metadata": {},
   "source": [
    "ver6为ssd_vgg16网络的map计算代码,不包括模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90ae3827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 21:18:31.104110: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import InputLayer, UnitNormalization\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, DepthwiseConv2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Flatten, Concatenate, Reshape, MaxPooling2D, Dropout, ZeroPadding2D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import InputSpec, Layer\n",
    "import tensorflow.keras.backend as K\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cfdc1e",
   "metadata": {},
   "source": [
    "# 1. ssd标准模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4feb97f",
   "metadata": {},
   "source": [
    "backbone采用vgg16   \n",
    "模型输入为300*300图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e2450e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16(input_layer, classes, weight_decay=5e-4):\n",
    "    \n",
    "    ## block 1\n",
    "    ## 300,300,3 -> 150,150,64\n",
    "    x = Conv2D(64, kernel_size=(3,3),  activation='relu',  padding='same', name='conv1_1', kernel_regularizer=l2(weight_decay))(input_layer)\n",
    "    x = Conv2D(64, kernel_size=(3,3),  activation='relu',  padding='same', name='conv1_2', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='maxpool_1')(x)\n",
    "    \n",
    "    # Block 2\n",
    "    # 150,150,64 -> 75,75,128\n",
    "    x = Conv2D(128, kernel_size=(3,3),  activation='relu',  padding='same', name='conv2_1', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(128, kernel_size=(3,3),  activation='relu',  padding='same', name='conv2_2', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='maxpool_2')(x)\n",
    "    \n",
    "    # Block 3\n",
    "    # 75,75,128 -> 38,38,256\n",
    "    x = Conv2D(256, kernel_size=(3,3),  activation='relu',  padding='same',  name='conv3_1', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(256, kernel_size=(3,3),  activation='relu',  padding='same', name='conv3_2', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(256, kernel_size=(3,3),  activation='relu',  padding='same', name='conv3_3', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='maxpool_3')(x)\n",
    "    \n",
    "    # Block 4\n",
    "    # 38,38,256 -> 19,19,512\n",
    "    x = Conv2D(512, kernel_size=(3,3),  activation='relu',  padding='same', name='conv4_1', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(512, kernel_size=(3,3),  activation='relu',  padding='same', name='conv4_2', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(512, kernel_size=(3,3),  activation='relu',  padding='same', name='conv4_3', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='maxpool_4')(x)\n",
    "    \n",
    "    # Block 5\n",
    "    # 19,19,512 -> 19,19,512\n",
    "    x = Conv2D(512, kernel_size=(3,3),  activation='relu',  padding='same',  name='conv5_1', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(512, kernel_size=(3,3),  activation='relu',  padding='same', name='conv5_2', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(512, kernel_size=(3,3),  activation='relu',  padding='same', name='conv5_3', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(1, 1), padding='same', name='maxpool_5')(x)\n",
    "    \n",
    "    # FC6\n",
    "    # 19,19,512 -> 19,19,1024\n",
    "    x = Conv2D(1024, kernel_size=(3,3),  activation='relu',  padding='same',  name='convfc_6', kernel_regularizer=l2(weight_decay))(x)\n",
    "    \n",
    "    # FC7\n",
    "    # 19,19,1024 -> 19,19,1024\n",
    "    x = Conv2D(1024, kernel_size=(1,1),  activation='relu',  padding='same', name='convfc_7', kernel_regularizer=l2(weight_decay))(x)\n",
    "    \n",
    "    # Block 6\n",
    "    # 19,19,512 -> 10,10,512\n",
    "    x = Conv2D(256, kernel_size=(1,1),  activation='relu',  padding='same', name='conv6_1', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = ZeroPadding2D(padding=((1, 1), (1, 1)), name='zeropad_1')(x)\n",
    "    x = Conv2D(512, kernel_size=(3,3),  strides=(2, 2), activation='relu',  padding='valid', name='conv6_2', kernel_regularizer=l2(weight_decay))(x)\n",
    "    \n",
    "    # Block 7\n",
    "    # 10,10,512 -> 5,5,256\n",
    "    x = Conv2D(128, kernel_size=(1,1),  activation='relu',  padding='same', name='conv7_1')(x)\n",
    "    x = ZeroPadding2D(padding=((1, 1), (1, 1)), name='zeropad_2')(x)\n",
    "    x = Conv2D(256, kernel_size=(3,3),  strides=(2, 2), activation='relu',  padding='valid', name='conv7_2')(x)\n",
    "    \n",
    "    # Block 8\n",
    "    # 5,5,256 -> 3,3,256\n",
    "    x = Conv2D(128, kernel_size=(1,1),  activation='relu',  padding='same', name='conv8_1')(x)\n",
    "    x = Conv2D(256, kernel_size=(3,3),  strides=(1, 1), activation='relu',  padding='valid', name='conv8_2')(x)\n",
    "    \n",
    "    # Block 9\n",
    "    # 3,3,256 -> 1,1,256\n",
    "    x = Conv2D(128, kernel_size=(1,1),  activation='relu',  padding='same', name='conv9_1')(x)\n",
    "    y = Conv2D(256, kernel_size=(3,3),  strides=(1, 1), activation='relu',  padding='valid', name='conv9_2')(x)\n",
    "    \n",
    "    model = keras.Model(input_layer, y)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436c2233",
   "metadata": {},
   "source": [
    "test code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af59a43",
   "metadata": {},
   "source": [
    "x = layers.Input([300,300,3], 21)\n",
    "model = vgg16(x, 21)\n",
    "m_layers = model.layers\n",
    "print(m_layers[23].name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57b62660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssd_300_v3(input_shape=[300,300,3], num_classes=21):\n",
    "    \n",
    "    \"\"\"\n",
    "    y1 = mobi_model.layers[69] 19*19\n",
    "    y2 = mobi_model.layers[81] 10*10\n",
    "    y3 = mobi_model.layers[87] 5*5\n",
    "    y4 = mobi_model.layers[93] 3*3\n",
    "    y5 = mobi_model.layers[99] 2*2\n",
    "    y6 = mobi_model.layers[105] 1*1\n",
    "    \"\"\"\n",
    "\n",
    "    in_layer = layers.Input(input_shape)\n",
    "    vgg16_ = vgg16(in_layer, num_classes)\n",
    "    \n",
    "    \n",
    "    ### ssd架构实现  \n",
    "    #  38*38  512\n",
    "    \n",
    "\n",
    "    x = UnitNormalization(axis=3)(vgg16_.layers[13].output)\n",
    "#    x = vgg16_.layers[13].output\n",
    "    num_anchor = 4\n",
    "    num_loc_pred= 4*num_anchor\n",
    "    loc1 = Conv2D(filters = num_loc_pred, kernel_size = (3,3), strides=(1,1),\n",
    "                      padding='same', use_bias = True)(x)\n",
    "    loc1 = Flatten()(loc1)  \n",
    "\n",
    "    num_cls_pred = num_classes*num_anchor\n",
    "    cls1 = Conv2D(filters = num_cls_pred, kernel_size = (3,3), strides=(1,1),\n",
    "                      padding='same', use_bias = True)(x)\n",
    "    cls1 = Flatten()(cls1)\n",
    "\n",
    "    # 对fc7层进行处理 \n",
    "    #。19*19   1024\n",
    "    num_anchor = 6\n",
    "    num_loc_pred= 4*num_anchor\n",
    "    loc2 = Conv2D(filters = num_loc_pred, kernel_size = (3,3), strides=(1,1),\n",
    "                      padding='same', use_bias = True)(vgg16_.layers[20].output)\n",
    "    loc2 = Flatten()(loc2)\n",
    "    \n",
    "    num_cls_pred = num_classes*num_anchor\n",
    "    cls2 = Conv2D(filters = num_cls_pred, kernel_size = (3,3), strides=(1,1),\n",
    "                      padding='same', use_bias = True)(vgg16_.layers[20].output)\n",
    "    cls2 = Flatten()(cls2)\n",
    "\n",
    "    ###  对conv6_2进行处理\n",
    "    #。10*10.  512\n",
    "    num_anchor = 6\n",
    "    num_loc_pred= 4*num_anchor\n",
    "    loc3 = Conv2D(filters = num_loc_pred, kernel_size = (3,3), strides=(1,1),\n",
    "                      padding='same', use_bias = True)(vgg16_.layers[23].output)\n",
    "    loc3 = Flatten()(loc3)\n",
    "    \n",
    "    num_cls_pred = num_classes*num_anchor\n",
    "    cls3 = Conv2D(filters = num_cls_pred, kernel_size = (3,3), strides=(1,1),\n",
    "                      padding='same', use_bias = True)(vgg16_.layers[23].output)\n",
    "    cls3 = Flatten()(cls3)\n",
    "\n",
    "    ### 对conv7_2进行处理\n",
    "    #。5*5.  256\n",
    "    num_anchor = 6\n",
    "    num_loc_pred= 4*num_anchor\n",
    "    loc4 = Conv2D(filters = num_loc_pred, kernel_size = (3,3), strides=(1,1),\n",
    "                      padding='same', use_bias = True)(vgg16_.layers[26].output)\n",
    "    loc4 = Flatten()(loc4)\n",
    "    \n",
    "    num_cls_pred = num_classes*num_anchor\n",
    "    cls4 = Conv2D(filters = num_cls_pred, kernel_size = (3,3), strides=(1,1),\n",
    "                      padding='same', use_bias = True)(vgg16_.layers[26].output)\n",
    "    cls4 = Flatten()(cls4)\n",
    "\n",
    "    ### 对conv8_2进行处理\n",
    "    #。3*3.    256\n",
    "    num_anchor = 4\n",
    "    num_loc_pred= 4*num_anchor\n",
    "    loc5 = Conv2D(filters = num_loc_pred, kernel_size = (3,3), strides=(1,1),\n",
    "                      padding='same', use_bias = True)(vgg16_.layers[28].output)\n",
    "    loc5 = Flatten()(loc5)\n",
    "    \n",
    "    num_cls_pred = num_classes*num_anchor\n",
    "    cls5 = Conv2D(filters = num_cls_pred, kernel_size = (3,3), strides=(1,1),\n",
    "                      padding='same', use_bias = True)(vgg16_.layers[28].output)\n",
    "    cls5 = Flatten()(cls5)\n",
    "    \n",
    "    #### 对conv9_2进行处理\n",
    "    #。1*1  256\n",
    "    num_anchor = 4\n",
    "    num_loc_pred= 4*num_anchor\n",
    "    loc6 = Conv2D(filters = num_loc_pred, kernel_size = (3,3), strides=(1,1), \n",
    "                      padding='same', use_bias = True)(vgg16_.layers[30].output)\n",
    "    loc6 = Flatten()(loc6)\n",
    "    \n",
    "    num_cls_pred = num_classes*num_anchor\n",
    "    cls6 = Conv2D(filters = num_cls_pred, kernel_size = (3,3), strides=(1,1), \n",
    "                      padding='same', use_bias = True)(vgg16_.layers[30].output)\n",
    "    cls6 = Flatten()(cls6)\n",
    "    \n",
    "    ## 多路输出合并\n",
    "    localisations = Concatenate(axis=1)([loc1, loc2, loc3, loc4,loc5, loc6])\n",
    "    localisations = Reshape((-1, 4))(localisations)\n",
    "    \n",
    "    logits = Concatenate(axis=1)([cls1, cls2, cls3, cls4, cls5, cls6])\n",
    "    logits = Reshape((-1, num_classes))(logits)   \n",
    "    logits = Activation('softmax')(logits)\n",
    "    \n",
    "    predictions = Concatenate(axis =-1)([localisations, logits])\n",
    "    \n",
    "    ssd_model = keras.Model(inputs=in_layer, outputs=predictions)\n",
    "    \n",
    "    return ssd_model \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397ead62",
   "metadata": {},
   "source": [
    "# 2. 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d0f207",
   "metadata": {},
   "source": [
    "各部分主要功能：\n",
    "\n",
    "1. 生成anchor_boxes.\n",
    "2. 从annotation文件加载图像和标注数据\n",
    "3. 计算满足匹配条件的先验框与真实框的相对误差值\n",
    "4. 根据真实框生成所有目标框的修正值(仅iou大于0.5的目标框为有效目标框的候选)\n",
    "5. 读取annotaion文件，生成训练数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e46957f",
   "metadata": {},
   "source": [
    "## 2.1 anchor_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a6675b",
   "metadata": {},
   "source": [
    "共有\n",
    "$38*38*4+19*19*6+10*10*6+5*5*6+3*3*4+1*1*4=8732$ \n",
    "个anchor_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d821870",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnchorBox():\n",
    "    def __init__(self, input_shape, min_size, max_size=None, aspect_ratios=None, flip=True):\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "        self.min_size = min_size\n",
    "        self.max_size = max_size\n",
    "\n",
    "        self.aspect_ratios = []\n",
    "        for ar in aspect_ratios:\n",
    "            self.aspect_ratios.append(ar)\n",
    "            self.aspect_ratios.append(1.0 / ar)\n",
    "\n",
    "    def call(self, layer_shape, mask=None):\n",
    "        # --------------------------------- #\n",
    "        #   获取输入进来的特征层的宽和高\n",
    "        #   比如38x38\n",
    "        # --------------------------------- #\n",
    "        layer_height    = layer_shape[0]\n",
    "        layer_width     = layer_shape[1]\n",
    "        # --------------------------------- #\n",
    "        #   获取输入进来的图片的宽和高\n",
    "        #   比如300x300\n",
    "        # --------------------------------- #\n",
    "        img_height  = self.input_shape[0]\n",
    "        img_width   = self.input_shape[1]\n",
    "\n",
    "        box_widths  = []\n",
    "        box_heights = []\n",
    "        # --------------------------------- #\n",
    "        #   self.aspect_ratios一般有两个值\n",
    "        #   [1, 1, 2, 1/2]\n",
    "        #   [1, 1, 2, 1/2, 3, 1/3]\n",
    "        # --------------------------------- #\n",
    "        for ar in self.aspect_ratios:\n",
    "            # 首先添加一个较小的正方形\n",
    "            if ar == 1 and len(box_widths) == 0:\n",
    "                box_widths.append(self.min_size)\n",
    "                box_heights.append(self.min_size)\n",
    "            # 然后添加一个较大的正方形\n",
    "            elif ar == 1 and len(box_widths) > 0:\n",
    "                box_widths.append(np.sqrt(self.min_size * self.max_size))\n",
    "                box_heights.append(np.sqrt(self.min_size * self.max_size))\n",
    "            # 然后添加长方形\n",
    "            elif ar != 1:\n",
    "                box_widths.append(self.min_size * np.sqrt(ar))\n",
    "                box_heights.append(self.min_size / np.sqrt(ar))\n",
    "\n",
    "        # --------------------------------- #\n",
    "        #   获得所有先验框的宽高1/2\n",
    "        # --------------------------------- #\n",
    "        box_widths  = 0.5 * np.array(box_widths)\n",
    "        box_heights = 0.5 * np.array(box_heights)\n",
    "\n",
    "        # --------------------------------- #\n",
    "        #   每一个特征层对应的步长\n",
    "        # --------------------------------- #\n",
    "        step_x = img_width / layer_width\n",
    "        step_y = img_height / layer_height\n",
    "\n",
    "        # --------------------------------- #\n",
    "        #   生成网格中心\n",
    "        # --------------------------------- #\n",
    "        linx = np.linspace(0.5 * step_x, img_width - 0.5 * step_x,\n",
    "                           layer_width)\n",
    "        liny = np.linspace(0.5 * step_y, img_height - 0.5 * step_y,\n",
    "                           layer_height)\n",
    "        centers_x, centers_y = np.meshgrid(linx, liny)\n",
    "        centers_x = centers_x.reshape(-1, 1)\n",
    "        centers_y = centers_y.reshape(-1, 1)\n",
    "\n",
    "        # 每一个先验框需要两个(centers_x, centers_y)，前一个用来计算左上角，后一个计算右下角\n",
    "        num_anchors_ = len(self.aspect_ratios)\n",
    "        anchor_boxes = np.concatenate((centers_x, centers_y), axis=1)\n",
    "        anchor_boxes = np.tile(anchor_boxes, (1, 2 * num_anchors_))\n",
    "        \n",
    "        # 获得先验框的左上角和右下角\n",
    "        anchor_boxes[:, ::4]    -= box_widths\n",
    "        anchor_boxes[:, 1::4]   -= box_heights\n",
    "        anchor_boxes[:, 2::4]   += box_widths\n",
    "        anchor_boxes[:, 3::4]   += box_heights\n",
    "\n",
    "        # --------------------------------- #\n",
    "        #   将先验框变成小数的形式\n",
    "        #   归一化\n",
    "        # --------------------------------- #\n",
    "        anchor_boxes[:, ::2]    /= img_width\n",
    "        anchor_boxes[:, 1::2]   /= img_height\n",
    "        anchor_boxes = anchor_boxes.reshape(-1, 4)\n",
    "\n",
    "        anchor_boxes = np.minimum(np.maximum(anchor_boxes, 0.0), 1.0)\n",
    "        return anchor_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b86f49af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------#\n",
    "#   用于ssd_mobilenet_V1计算共享特征层的大小\n",
    "#---------------------------------------------------#\n",
    "def get_img_output_length(height, width):\n",
    "    filter_sizes    = [3, 3, 3, 3, 3, 3, 3, 3]\n",
    "    padding         = [1, 1, 1, 1, 1, 1, 0, 0]\n",
    "    stride          = [2, 2, 2, 2, 2, 2, 1, 1]\n",
    "    feature_heights = []\n",
    "    feature_widths  = []\n",
    "\n",
    "    for i in range(len(filter_sizes)):\n",
    "        height  = (height + 2*padding[i] - filter_sizes[i]) // stride[i] + 1\n",
    "        width   = (width + 2*padding[i] - filter_sizes[i]) // stride[i] + 1\n",
    "        feature_heights.append(height)\n",
    "        feature_widths.append(width)\n",
    "    return np.array(feature_heights)[-6:], np.array(feature_widths)[-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9374c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anchors(input_shape = [300,300], anchors_size = [30, 60, 111, 162, 213, 264, 315]):\n",
    "    feature_heights, feature_widths = get_img_output_length(input_shape[0], input_shape[1])\n",
    "    aspect_ratios = [[1, 2], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2], [1, 2]]\n",
    "    anchors = []\n",
    "    for i in range(len(feature_heights)):\n",
    "        anchors.append(AnchorBox(input_shape, anchors_size[i], max_size = anchors_size[i+1], \n",
    "                    aspect_ratios = aspect_ratios[i]).call([feature_heights[i], feature_widths[i]]))\n",
    "\n",
    "    anchors = np.concatenate(anchors, axis=0)\n",
    "\n",
    "    return anchors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6e4888",
   "metadata": {},
   "source": [
    "# 2. 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e439d018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from PIL import ImageDraw, ImageFont\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca3aa59",
   "metadata": {},
   "source": [
    "## 2.0 用到的函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c435dafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------#\n",
    "#   获得分类\n",
    "#---------------------------------------------------#\n",
    "def get_classes(classes_path):\n",
    "    with open(classes_path, encoding='utf-8') as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names, len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22697654",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------#\n",
    "#   对输入图像进行resize\n",
    "#---------------------------------------------------#\n",
    "def resize_image(image, size, letterbox_image=False):\n",
    "    iw, ih  = image.size\n",
    "    w, h    = size\n",
    "    if letterbox_image:\n",
    "        scale   = min(w/iw, h/ih)\n",
    "        nw      = int(iw*scale)\n",
    "        nh      = int(ih*scale)\n",
    "\n",
    "        image   = image.resize((nw,nh), Image.BICUBIC)\n",
    "        new_image = Image.new('RGB', size, (128,128,128))\n",
    "        new_image.paste(image, ((w-nw)//2, (h-nh)//2))\n",
    "    else:\n",
    "        new_image = image.resize((w, h), Image.BICUBIC)\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a56dfc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BBoxUtility(object):\n",
    "    def __init__(self, num_classes, nms_thresh=0.45, top_k=30):\n",
    "        self.num_classes    = num_classes\n",
    "        self._nms_thresh    = nms_thresh\n",
    "        self._top_k         = top_k\n",
    "        \n",
    "    def ssd_correct_boxes(self, box_xy, box_wh, image_shape, letterbox_image=False):\n",
    "        #-----------------------------------------------------------------#\n",
    "        #   把y轴放前面是因为方便预测框和图像的宽高进行相乘\n",
    "        #-----------------------------------------------------------------#\n",
    "        box_yx = box_xy[..., ::-1]\n",
    "        box_hw = box_wh[..., ::-1]\n",
    "\n",
    "        image_shape = np.array(image_shape)\n",
    "\n",
    "        box_mins    = box_yx - (box_hw / 2.)\n",
    "        box_maxes   = box_yx + (box_hw / 2.)\n",
    "        boxes  = np.concatenate([box_mins[..., 0:1], box_mins[..., 1:2], box_maxes[..., 0:1], box_maxes[..., 1:2]], axis=-1)\n",
    "        boxes *= np.concatenate([image_shape, image_shape], axis=-1)\n",
    "        return boxes\n",
    "\n",
    "    def decode_boxes(self, mbox_loc, anchors, variances):\n",
    "        # 获得先验框的宽与高\n",
    "        anchor_width     = anchors[:, 2] - anchors[:, 0]\n",
    "        anchor_height    = anchors[:, 3] - anchors[:, 1]\n",
    "        # 获得先验框的中心点\n",
    "        anchor_center_x  = 0.5 * (anchors[:, 2] + anchors[:, 0])\n",
    "        anchor_center_y  = 0.5 * (anchors[:, 3] + anchors[:, 1])\n",
    "\n",
    "        # 真实框距离先验框中心的xy轴偏移情况\n",
    "        decode_bbox_center_x = mbox_loc[:, 0] * anchor_width * variances[0]\n",
    "        decode_bbox_center_x += anchor_center_x\n",
    "        decode_bbox_center_y = mbox_loc[:, 1] * anchor_height * variances[1]\n",
    "        decode_bbox_center_y += anchor_center_y\n",
    "        \n",
    "        # 真实框的宽与高的求取\n",
    "        decode_bbox_width   = np.exp(mbox_loc[:, 2] * variances[2])\n",
    "        decode_bbox_width   *= anchor_width\n",
    "        decode_bbox_height  = np.exp(mbox_loc[:, 3] * variances[3])\n",
    "        decode_bbox_height  *= anchor_height\n",
    "\n",
    "        # 获取真实框的左上角与右下角\n",
    "        decode_bbox_xmin = decode_bbox_center_x - 0.5 * decode_bbox_width\n",
    "        decode_bbox_ymin = decode_bbox_center_y - 0.5 * decode_bbox_height\n",
    "        decode_bbox_xmax = decode_bbox_center_x + 0.5 * decode_bbox_width\n",
    "        decode_bbox_ymax = decode_bbox_center_y + 0.5 * decode_bbox_height\n",
    "\n",
    "        # 真实框的左上角与右下角进行堆叠\n",
    "        decode_bbox = np.concatenate((decode_bbox_xmin[:, None],\n",
    "                                      decode_bbox_ymin[:, None],\n",
    "                                      decode_bbox_xmax[:, None],\n",
    "                                      decode_bbox_ymax[:, None]), axis=-1)\n",
    "        # 防止超出0与1\n",
    "        decode_bbox = np.minimum(np.maximum(decode_bbox, 0.0), 1.0)\n",
    "        return decode_bbox\n",
    "\n",
    "    def decode_box(self, predictions, anchors, image_shape, letterbox_image=False, variances = [0.1, 0.1, 0.2, 0.2], confidence=0.5):\n",
    "        #---------------------------------------------------#\n",
    "        #   :4是回归预测结果\n",
    "        #---------------------------------------------------#\n",
    "        mbox_loc        = predictions[:, :, :4]\n",
    "        #---------------------------------------------------#\n",
    "        #   获得种类的置信度\n",
    "        #---------------------------------------------------#\n",
    "        mbox_conf       = predictions[:, :, 4:]\n",
    "\n",
    "        results = []\n",
    "        #----------------------------------------------------------------------------------------------------------------#\n",
    "        #   对每一张图片进行处理，由于在predict.py的时候，我们只输入一张图片，所以for i in range(len(mbox_loc))只进行一次\n",
    "        #----------------------------------------------------------------------------------------------------------------#\n",
    "        for i in range(len(mbox_loc)):\n",
    "            results.append([])\n",
    "            #--------------------------------#\n",
    "            #   利用回归结果对先验框进行解码\n",
    "            #--------------------------------#\n",
    "            decode_bbox = self.decode_boxes(mbox_loc[i], anchors, variances)\n",
    "\n",
    "            for c in range(1, self.num_classes):\n",
    "                #--------------------------------#\n",
    "                #   取出属于该类的所有框的置信度\n",
    "                #   判断是否大于门限\n",
    "                #--------------------------------#\n",
    "                c_confs     = mbox_conf[i, :, c]\n",
    "                c_confs_m   = c_confs > confidence\n",
    "                if len(c_confs[c_confs_m]) > 0:\n",
    "                    #-----------------------------------------#\n",
    "                    #   取出得分高于confidence的框\n",
    "                    #-----------------------------------------#\n",
    "                    boxes_to_process = decode_bbox[c_confs_m]\n",
    "                    confs_to_process = c_confs[c_confs_m]\n",
    "                    #-----------------------------------------#\n",
    "                    #   进行iou的非极大抑制\n",
    "                    #-----------------------------------------#\n",
    "                    idx = tf.image.non_max_suppression(tf.cast(boxes_to_process,tf.float32), tf.cast(confs_to_process,tf.float32),\n",
    "                                            self._top_k,\n",
    "                                            iou_threshold=self._nms_thresh).numpy()\n",
    "                    #-----------------------------------------#\n",
    "                    #   取出在非极大抑制中效果较好的内容\n",
    "                    #-----------------------------------------#\n",
    "                    good_boxes  = boxes_to_process[idx]\n",
    "                    confs       = confs_to_process[idx][:, None]\n",
    "                    labels      = (c - 1) * np.ones((len(idx), 1))\n",
    "                    #-----------------------------------------#\n",
    "                    #   将label、置信度、框的位置进行堆叠。\n",
    "                    #-----------------------------------------#\n",
    "                    c_pred      = np.concatenate((good_boxes, labels, confs), axis=1)\n",
    "                    # 添加进result里\n",
    "                    results[-1].extend(c_pred)\n",
    "\n",
    "            if len(results[-1]) > 0:\n",
    "                results[-1] = np.array(results[-1])\n",
    "                box_xy, box_wh = (results[-1][:, 0:2] + results[-1][:, 2:4])/2, results[-1][:, 2:4] - results[-1][:, 0:2]\n",
    "                results[-1][:, :4] = self.ssd_correct_boxes(box_xy, box_wh, image_shape)\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2634f218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvtColor(image):\n",
    "    if len(np.shape(image))==3 and np.shape(image)[2]==3:\n",
    "        return image\n",
    "    else:\n",
    "        image = image.convert('RGB')\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bd97b7",
   "metadata": {},
   "source": [
    "## 2.2 参数设置和模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "79b20bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_path = 'model_data/voc_classes.txt'\n",
    "#---------------------------------------------------------------------#\n",
    "#   用于预测的图像大小，和train时使用同一个即可\n",
    "#---------------------------------------------------------------------#\n",
    "input_shape = [300, 300]\n",
    "#---------------------------------------------------------------------#\n",
    "#   只有得分大于置信度的预测框会被保留下来\n",
    "#---------------------------------------------------------------------#\n",
    "confidence = 0.5\n",
    "#---------------------------------------------------------------------#\n",
    "#   非极大抑制所用到的nms_iou大小\n",
    "#---------------------------------------------------------------------#\n",
    "nms_iou = 0.45\n",
    "#---------------------------------------------------------------------#\n",
    "#   用于指定先验框的大小\n",
    "#---------------------------------------------------------------------#\n",
    "anchors_size  =  [30, 60, 111, 162, 213, 264, 315]\n",
    "#---------------------------------------------------------------------#\n",
    "#   该变量用于控制是否使用letterbox_image对输入图像进行不失真的resize，\n",
    "#   在多次测试后，发现关闭letterbox_image直接resize的效果更好\n",
    "#---------------------------------------------------------------------#\n",
    "#letterbox_image =  False\n",
    "\n",
    "#---------------------------------------------------------------------#\n",
    "#    保存整个测试集的路径\n",
    "#---------------------------------------------------------------------#\n",
    "test_annotation_path = '2007_test.txt'\n",
    "prediction_path = 'pred_result/'\n",
    "\n",
    "saved_model = \"model_data/voc_trained_weights_1207_0227_5.h5\"\n",
    "classes_path    = 'model_data/voc_classes.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad889c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The {:d} figure have been predicted! 0\n",
      "The {:d} figure have been predicted! 100\n",
      "The {:d} figure have been predicted! 200\n",
      "The {:d} figure have been predicted! 300\n",
      "The {:d} figure have been predicted! 400\n",
      "The {:d} figure have been predicted! 500\n",
      "The {:d} figure have been predicted! 600\n",
      "The {:d} figure have been predicted! 700\n",
      "The {:d} figure have been predicted! 800\n",
      "The {:d} figure have been predicted! 900\n",
      "The {:d} figure have been predicted! 1000\n",
      "The {:d} figure have been predicted! 1100\n",
      "The {:d} figure have been predicted! 1200\n",
      "The {:d} figure have been predicted! 1300\n",
      "The {:d} figure have been predicted! 1400\n",
      "The {:d} figure have been predicted! 1500\n",
      "The {:d} figure have been predicted! 1600\n",
      "The {:d} figure have been predicted! 1700\n",
      "The {:d} figure have been predicted! 1800\n",
      "The {:d} figure have been predicted! 1900\n",
      "The {:d} figure have been predicted! 2000\n",
      "The {:d} figure have been predicted! 2100\n",
      "The {:d} figure have been predicted! 2200\n",
      "The {:d} figure have been predicted! 2300\n",
      "The {:d} figure have been predicted! 2400\n",
      "The {:d} figure have been predicted! 2500\n",
      "The {:d} figure have been predicted! 2600\n",
      "The {:d} figure have been predicted! 2700\n",
      "The {:d} figure have been predicted! 2800\n",
      "The {:d} figure have been predicted! 2900\n",
      "The {:d} figure have been predicted! 3000\n",
      "The {:d} figure have been predicted! 3100\n",
      "The {:d} figure have been predicted! 3200\n",
      "The {:d} figure have been predicted! 3300\n",
      "The {:d} figure have been predicted! 3400\n",
      "The {:d} figure have been predicted! 3500\n",
      "The {:d} figure have been predicted! 3600\n",
      "The {:d} figure have been predicted! 3700\n",
      "The {:d} figure have been predicted! 3800\n",
      "The {:d} figure have been predicted! 3900\n",
      "The {:d} figure have been predicted! 4000\n",
      "The {:d} figure have been predicted! 4100\n",
      "The {:d} figure have been predicted! 4200\n",
      "The {:d} figure have been predicted! 4300\n",
      "The {:d} figure have been predicted! 4400\n",
      "The {:d} figure have been predicted! 4500\n",
      "The {:d} figure have been predicted! 4600\n",
      "The {:d} figure have been predicted! 4700\n",
      "The {:d} figure have been predicted! 4800\n",
      "The {:d} figure have been predicted! 4900\n"
     ]
    }
   ],
   "source": [
    "### 1. 获得分类名称和数量\n",
    "class_names, num_classes = get_classes(classes_path)\n",
    "anchors = get_anchors(input_shape, anchors_size)\n",
    "\n",
    "### 2. 生成预测结果集合\n",
    "preds = {}\n",
    "for i in range(num_classes):\n",
    "    preds[class_names[i]]= []\n",
    "\n",
    "### 3. bbox辅助对象\n",
    "bbox_util = BBoxUtility(num_classes+1, nms_thresh=nms_iou)\n",
    "\n",
    "### 3. 读取数据集对应的txt\n",
    "\n",
    "with open(test_annotation_path, encoding='utf-8') as f:\n",
    "    test_lines = f.readlines()\n",
    "num_testfile   = len(test_lines)\n",
    "\n",
    "### 4. 加载模型\n",
    "ssd_model = ssd_300_v3([input_shape[0], input_shape[1], 3], num_classes+1)\n",
    "ssd_model.load_weights(saved_model)\n",
    "\n",
    "### 5. 预测\n",
    "for i in range(num_testfile):\n",
    "    #预处理代码需要修改\n",
    "#    image, box = get_random_data(test_lines[i], input_shape, random=train)\n",
    "    line = test_lines[i].split()\n",
    "    image = Image.open(line[0])\n",
    "    image_shape = np.array(np.shape(image)[0:2])\n",
    "    image_filename = line[0].split(\"/\")[-1]\n",
    "    image_idx = image_filename.split(\".\")[0]\n",
    "    \n",
    "    image_data  = resize_image(image, (input_shape[0], input_shape[1]))\n",
    "\n",
    "    image_data  = preprocess_input(np.expand_dims(np.array(image_data, dtype='float32'), 0))\n",
    "\n",
    "    m_pred = ssd_model(image_data, training=False).numpy() #小数据集用本方法 后续考虑用predict方法\n",
    "    results     = bbox_util.decode_box(m_pred, anchors, image_shape, \n",
    "                    confidence=confidence)\n",
    "\n",
    "    if len(results[0])>0:\n",
    "        top_label   = np.array(results[0][:, 4], dtype = 'int32')\n",
    "        top_conf    = results[0][:, 5]\n",
    "        top_boxes   = results[0][:, :4]\n",
    "        for j, c in list(enumerate(top_label)):\n",
    "            res = []\n",
    "            predicted_class = class_names[int(c)]\n",
    "            res.append(image_idx)\n",
    "            res.append(top_conf[j])\n",
    "            res.append(top_boxes[j])\n",
    "            preds[predicted_class].append(res)\n",
    "    if i%100==0:\n",
    "        print(\"The {:d} figure have been predicted!\", i)\n",
    "\n",
    "# 6. 保存预测结果\n",
    "if not os.path.isdir(prediction_path):\n",
    "    os.mkdir(prediction_path)\n",
    "\n",
    "for i in range(num_classes):\n",
    "    pred_file = prediction_path+class_names[i]+'.txt' \n",
    "    with open(pred_file, 'w') as f: \n",
    "        for j in range(len(preds[class_names[i]])):\n",
    "            data = preds[class_names[i]][j]\n",
    "            top, left, bottom, right = data[2]\n",
    "            top     = max(0, np.floor(top).astype('int32'))\n",
    "            left    = max(0, np.floor(left).astype('int32'))\n",
    "            bottom  = min(image.size[1], np.floor(bottom).astype('int32'))\n",
    "            right   = min(image.size[0], np.floor(right).astype('int32'))\n",
    "            \n",
    "            \n",
    "            # 标注数据的格式应当按照 xmin ，ymin， xmax， ymax来写，而不是行，列的 顺序\n",
    "            label = '{} {:.2f} {} {} {} {}'.format(data[0], data[1], left, top, right, bottom)\n",
    "            f.write(label+'\\n')\n",
    "        f.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd9f4ef",
   "metadata": {},
   "source": [
    "# 3. 模型预测结果MAP计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "617fe7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cPickle\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "098e9bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 从标注文件获取真实的标注结果\n",
    "def parse_rec(filename):\n",
    "    \"\"\"Parse a PASCAL VOC xml file.\"\"\"\n",
    "    # 返回一个列表，列表中的每个元素是一个字典\n",
    "    tree = ET.parse(filename)\n",
    "    objects = []\n",
    "    for obj in tree.findall('object'):\n",
    "        obj_struct = {}\n",
    "        obj_struct['name'] = obj.find('name').text\n",
    "        obj_struct['pose'] = obj.find('pose').text\n",
    "        obj_struct['truncated'] = int(obj.find('truncated').text)\n",
    "        obj_struct['difficult'] = int(obj.find('difficult').text)\n",
    "        bbox = obj.find('bndbox')\n",
    "        obj_struct['bbox'] = [int(bbox.find('xmin').text),\n",
    "                              int(bbox.find('ymin').text),\n",
    "                              int(bbox.find('xmax').text),\n",
    "                              int(bbox.find('ymax').text)]\n",
    "        objects.append(obj_struct)\n",
    "\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b780488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "\n",
    "def voc_ap(rec, prec, use_07_metric=False):\n",
    "    \"\"\"Compute VOC AP given precision and recall. If use_07_metric is true, uses\n",
    "    the VOC 07 11-point method (default:False).\n",
    "    \"\"\"\n",
    "    if use_07_metric:\n",
    "        # 11 point metric\n",
    "        ap = 0.\n",
    "        for t in np.arange(0., 1.1, 0.1):\n",
    "            if np.sum(rec >= t) == 0:\n",
    "                p = 0\n",
    "            else:\n",
    "                p = np.max(prec[rec >= t])\n",
    "            ap = ap + p / 11.\n",
    "    else:\n",
    "        # correct AP calculation\n",
    "        # first append sentinel values at the end\n",
    "        mrec = np.concatenate(([0.], rec, [1.]))\n",
    "        mpre = np.concatenate(([0.], prec, [0.]))\n",
    "\n",
    "        # compute the precision envelope\n",
    "        for i in range(mpre.size - 1, 0, -1):\n",
    "            mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "        # to calculate area under PR curve, look for points\n",
    "        # where X axis (recall) changes value\n",
    "        i = np.where(mrec[1:] != mrec[:-1])[0] #i位数组\n",
    "\n",
    "        # and sum (\\Delta recall) * prec\n",
    "        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])  #ap为数组\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6fabd2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def voc_eval(detpath,\n",
    "             annopath,\n",
    "             imagesetfile,\n",
    "             classname,\n",
    "             ovthresh=0.5,\n",
    "             use_07_metric=False):\n",
    "    \"\"\"rec, prec, ap = voc_eval(detpath,\n",
    "                                annopath,\n",
    "                                imagesetfile,\n",
    "                                classname,\n",
    "                                [ovthresh],\n",
    "                                [use_07_metric])\n",
    "    Top level function that does the PASCAL VOC evaluation.\n",
    "    detpath: Path to detections  #检测结果路径\n",
    "        detpath.format(classname) should produce the detection results file.\n",
    "    annopath: Path to annotations  #标注文件路径\n",
    "        annopath.format(imagename) should be the xml annotations file.\n",
    "    imagesetfile: Text file containing the list of images, one image per line.  #图像集文件名列表文件\n",
    "    classname: Category name (duh)    # 分类名称\n",
    "    [ovthresh]: Overlap threshold (default = 0.5)\n",
    "    [use_07_metric]: Whether to use VOC07's 11 point AP computation\n",
    "        (default False)\n",
    "    \"\"\"\n",
    "    # assumes detections are in detpath.format(classname)\n",
    "    # assumes annotations are in annopath.format(imagename)\n",
    "    # assumes imagesetfile is a text file with each line an image name\n",
    "    # cachedir caches the annotations in a pickle file\n",
    "\n",
    "    imageset = os.path.splitext(os.path.basename(imagesetfile))[0]  #获得图像集说明文件的名称\n",
    "    with open(imagesetfile, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    imagenames = [x.strip() for x in lines]   ##获得图像集文件名列表\n",
    "\n",
    "    recs = {}\n",
    "    for i, imagename in enumerate(imagenames):\n",
    "        recs[imagename] = parse_rec(annopath.format(imagename))\n",
    "        if i % 100 == 0:\n",
    "            logger.info(\n",
    "                'Reading annotation for {:d}/{:d}'.format(\n",
    "                    i + 1, len(imagenames)))\n",
    "\n",
    "    # extract gt objects for this class\n",
    "    class_recs = {}\n",
    "    npos = 0\n",
    "    for imagename in imagenames:\n",
    "        R = [obj for obj in recs[imagename] if obj['name'] == classname]\n",
    "        bbox = np.array([x['bbox'] for x in R])\n",
    "        difficult = np.array([x['difficult'] for x in R]).astype(np.bool_)\n",
    "        det = [False] * len(R)\n",
    "        npos = npos + sum(~difficult)\n",
    "        class_recs[imagename] = {'bbox': bbox,\n",
    "                                 'difficult': difficult,\n",
    "                                 'det': det}\n",
    "\n",
    "    # read dets\n",
    "    detfile = detpath.format(classname)  #一个检测结果为文件中的一行，一张图有多个检测结果就有多行\n",
    "    with open(detfile, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    splitlines = [x.strip().split(' ') for x in lines]\n",
    "    image_ids = [x[0] for x in splitlines]\n",
    "\n",
    "    confidence = np.array([float(x[1]) for x in splitlines])\n",
    "    BB = np.array([[float(z) for z in x[2:]] for x in splitlines])\n",
    "\n",
    "    # sort by confidence 按照降序排列，高置信度在前\n",
    "    sorted_ind = np.argsort(-confidence)\n",
    "    BB = BB[sorted_ind, :]\n",
    "    image_ids = [image_ids[x] for x in sorted_ind]  #预测出xx类目标的图像列表\n",
    "\n",
    "    # go down dets and mark TPs and FPs\n",
    "    nd = len(image_ids)\n",
    "    tp = np.zeros(nd)   # true predict\n",
    "    fp = np.zeros(nd)   # false predict\n",
    "    for d in range(nd):\n",
    "        R = class_recs[image_ids[d]]   #xx图对应的gt标注数据\n",
    "        bb = BB[d, :].astype(float)    #xx图的预测结果坐标\n",
    "        ovmax = -np.inf\n",
    "        BBGT = R['bbox'].astype(float)\n",
    "\n",
    "        if BBGT.size > 0:               #预测框与该图所有的gt框做重叠计算，找到重合度最大的框\n",
    "            # compute overlaps\n",
    "            # intersection\n",
    "            ixmin = np.maximum(BBGT[:, 0], bb[0])\n",
    "            iymin = np.maximum(BBGT[:, 1], bb[1])\n",
    "            ixmax = np.minimum(BBGT[:, 2], bb[2])\n",
    "            iymax = np.minimum(BBGT[:, 3], bb[3])\n",
    "            iw = np.maximum(ixmax - ixmin + 1., 0.)\n",
    "            ih = np.maximum(iymax - iymin + 1., 0.)\n",
    "            inters = iw * ih\n",
    "\n",
    "            # union\n",
    "            uni = ((bb[2] - bb[0] + 1.) * (bb[3] - bb[1] + 1.) +\n",
    "                   (BBGT[:, 2] - BBGT[:, 0] + 1.) *\n",
    "                   (BBGT[:, 3] - BBGT[:, 1] + 1.) - inters)\n",
    "\n",
    "            overlaps = inters / uni\n",
    "            ovmax = np.max(overlaps)\n",
    "            jmax = np.argmax(overlaps)\n",
    "\n",
    "        if ovmax > ovthresh:\n",
    "            if not R['difficult'][jmax]:\n",
    "                if not R['det'][jmax]:\n",
    "                    tp[d] = 1.\n",
    "                    R['det'][jmax] = 1\n",
    "                else:\n",
    "                    fp[d] = 1.\n",
    "        else:\n",
    "            fp[d] = 1.\n",
    "    # compute precision recall\n",
    "    fp = np.cumsum(fp)    #维度相加，得到错误检测结果累计数组\n",
    "    tp = np.cumsum(tp)    #维度相加，得到正确检测结果累计数组\n",
    "    rec = tp / float(npos)  #正确目标检测完成率\n",
    "    # avoid divide by zero in case the first detection matches a difficult\n",
    "    # ground truth\n",
    "    prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)  #检测结果正确率\n",
    "    ap = voc_ap(rec, prec, use_07_metric)\n",
    "\n",
    "    return rec, prec, ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ca772d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_rec 0.5964912280701754\n",
      "c_prec 0.8673469387755102\n",
      "c_ap 0.5853273308764004\n",
      "c_rec 0.7091988130563798\n",
      "c_prec 0.8047138047138047\n",
      "c_ap 0.6430750033036963\n",
      "c_rec 0.5838779956427015\n",
      "c_prec 0.8195718654434251\n",
      "c_ap 0.5403300764243442\n",
      "c_rec 0.4790874524714829\n",
      "c_prec 0.72\n",
      "c_ap 0.4254839796771143\n",
      "c_rec 0.3070362473347548\n",
      "c_prec 0.6697674418604651\n",
      "c_ap 0.2524656600713079\n",
      "c_rec 0.7089201877934272\n",
      "c_prec 0.798941798941799\n",
      "c_ap 0.6500273343904899\n",
      "c_rec 0.6319733555370525\n",
      "c_prec 0.7689969604863222\n",
      "c_ap 0.5573528896904844\n",
      "c_rec 0.8184357541899442\n",
      "c_prec 0.8207282913165266\n",
      "c_ap 0.7557350670878864\n",
      "c_rec 0.41005291005291006\n",
      "c_prec 0.5719557195571956\n",
      "c_ap 0.2962626069167901\n",
      "c_rec 0.5245901639344263\n",
      "c_prec 0.757396449704142\n",
      "c_ap 0.4516295585418265\n",
      "c_rec 0.7233009708737864\n",
      "c_prec 0.6898148148148148\n",
      "c_ap 0.666452185821278\n",
      "c_rec 0.7934560327198364\n",
      "c_prec 0.7054545454545454\n",
      "c_ap 0.7109634579833632\n",
      "c_rec 0.8017241379310345\n",
      "c_prec 0.8063583815028902\n",
      "c_ap 0.7680888258495153\n",
      "c_rec 0.6615384615384615\n",
      "c_prec 0.8365758754863813\n",
      "c_ap 0.5902723790141604\n",
      "c_rec 0.5814929328621908\n",
      "c_prec 0.7251445882676949\n",
      "c_ap 0.4744307835073766\n",
      "c_rec 0.42083333333333334\n",
      "c_prec 0.5611111111111111\n",
      "c_ap 0.30786810811720466\n",
      "c_rec 0.5082644628099173\n",
      "c_prec 0.6507936507936508\n",
      "c_ap 0.4235756877992143\n",
      "c_rec 0.6569037656903766\n",
      "c_prec 0.6487603305785123\n",
      "c_ap 0.5233686217091422\n",
      "c_rec 0.7907801418439716\n",
      "c_prec 0.8352059925093633\n",
      "c_ap 0.7485615393894649\n",
      "c_rec 0.5876623376623377\n",
      "c_prec 0.7448559670781894\n",
      "c_ap 0.4897648788837379\n",
      "The average ap of ssg_vgg16 for VOC dataset is {:d}. 0.5430517987527399\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "detpath = 'pred_result/{:s}.txt'\n",
    "annopath = '/home/whd/work/deeplearn/data/VOC_data/VOC_2007/VOC2007_test/Annotations/{:s}.xml'\n",
    "imagesetfile='test.txt'\n",
    "c_recs=[]\n",
    "c_precs = []\n",
    "c_aps = []\n",
    "for i in range(num_classes):\n",
    "    c_rec, c_prec, c_ap = voc_eval(detpath, annopath, imagesetfile, class_names[i])\n",
    "    print(\"c_rec\", c_rec[-1])\n",
    "    print(\"c_prec\", c_prec[-1])\n",
    "    print(\"c_ap\", c_ap)\n",
    "    c_recs.append(c_rec)\n",
    "    c_precs.append(c_prec)\n",
    "    c_aps.append(c_ap)\n",
    "\n",
    "#rec_ave = np.mean(np.array(c_recs))\n",
    "#prec_ave = np.mean(np.array(c_precs))\n",
    "ap_ave = np.mean(np.array(c_aps))\n",
    "#print(\"The average recall rate of ssg_vgg16 for VOC dataset is {:d}.\", rec_ave)\n",
    "#print(\"The average precision rate of ssg_vgg16 for VOC dataset is {:d}.\", prec_ave)\n",
    "print(\"The average ap of ssg_vgg16 for VOC dataset is {:d}.\", ap_ave)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0318a6b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c27050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
